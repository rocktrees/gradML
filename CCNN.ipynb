{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv3x3:\n",
    "      # A Convolution layer using 3x3 filters.\n",
    "\n",
    "  def __init__(self, num_filters):\n",
    "    self.num_filters = num_filters\n",
    "\n",
    "    # filters is a 3d array with dimensions (num_filters, 3, 3)\n",
    "    # We divide by 9 to reduce the variance of our initial values\n",
    "    self.filters = np.random.randn(num_filters, 3, 3) / 9\n",
    "\n",
    "  def iterate_regions(self, image):\n",
    "    '''\n",
    "    This actaully produces a region of an image that also captures its DEPTH\n",
    "    '''\n",
    "    h, w, _ = image.shape\n",
    "\n",
    "    for i in range(h - 2):\n",
    "      for j in range(w - 2):\n",
    "        im_region = image[i:(i + 3), j:(j + 3)]\n",
    "        yield im_region, i, j\n",
    "\n",
    "  def forward(self, input):\n",
    "    '''\n",
    "    Performs a forward pass of the conv layer using the given input.\n",
    "    Returns a 3d numpy array with dimensions (h, w, num_filters).\n",
    "    - input is a 2d numpy array\n",
    "    '''\n",
    "    self.last_input = input\n",
    "\n",
    "    # change here. Origionally, it didnt take in the \"num_filters\"(this is just the depth).\n",
    "    # So now instead of using self.filter which will always be (3,3,8), we use the depth of the given image\n",
    "    # And to make this simpler/better, we should only throw in the full RGB np.array, instead of grayscale.\n",
    "    # so for ex) first pass will have k = 3, then k = 3 * 8, ...\n",
    "    h, w, num_filters = input.shape\n",
    "    output = np.zeros((h - 2, w - 2, num_filters))\n",
    "    #print(f\"output shape: {output.shape}\")\n",
    "\n",
    "    # we must apply the filters to regions for each filter, one by one.\n",
    "    for fdx, f in enumerate(self.filters):# new\n",
    "      for im_region, i, j in self.iterate_regions(input):\n",
    "\n",
    "        #print(f\"imregion: {im_region.shape}\")\n",
    "        #print(f\"filter shapeL: {f.shape}\")\n",
    "        output[i, j] = np.sum(im_region * f, axis=(1, 2)) # new    \n",
    "        #output[i, j] = np.sum(im_region * self.filters, axis=(1, 2))\n",
    "\n",
    "    return output\n",
    "\n",
    "  def backprop(self, d_L_d_out, learn_rate):\n",
    "      '''\n",
    "      Performs a backward pass of the conv layer.\n",
    "      - d_L_d_out is the loss gradient for this layer's outputs.\n",
    "      - learn_rate is a float.\n",
    "\n",
    "\n",
    "      Used ChatGPT to create an output here.... NEED TO TEST\n",
    "      '''\n",
    "      d_L_d_filters = np.zeros(self.filters.shape)\n",
    "      d_L_d_input = np.zeros(self.last_input.shape)  # Gradient w.r.t input\n",
    "\n",
    "      for im_region, i, j in self.iterate_regions(self.last_input):\n",
    "          for f in range(self.num_filters):\n",
    "              d_L_d_filters[f] += d_L_d_out[i, j, f] * im_region\n",
    "              d_L_d_input[i:i+3, j:j+3] += d_L_d_out[i, j, f] * self.filters[f]\n",
    "\n",
    "      # Update filters\n",
    "      self.filters -= learn_rate * d_L_d_filters\n",
    "\n",
    "      # return the loss gradient for this layer's inputs\n",
    "      return d_L_d_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MaxPool2:\n",
    "  # A Max Pooling layer using a pool size of 2.\n",
    "\n",
    "  def iterate_regions(self, image):\n",
    "    '''\n",
    "    Generates non-overlapping 2x2 image regions to pool over.\n",
    "    - image is a 2d numpy array\n",
    "    '''\n",
    "    h, w, _ = image.shape\n",
    "    new_h = h // 2\n",
    "    new_w = w // 2\n",
    "\n",
    "    for i in range(new_h):\n",
    "      for j in range(new_w):\n",
    "        im_region = image[(i * 2):(i * 2 + 2), (j * 2):(j * 2 + 2)]\n",
    "        yield im_region, i, j\n",
    "\n",
    "  def forward(self, input):\n",
    "    '''\n",
    "    Performs a forward pass of the maxpool layer using the given input.\n",
    "    Returns a 3d numpy array with dimensions (h / 2, w / 2, num_filters).\n",
    "    - input is a 3d numpy array with dimensions (h, w, num_filters)\n",
    "    '''\n",
    "    self.last_input = input\n",
    "\n",
    "    h, w, num_filters = input.shape\n",
    "    output = np.zeros((h // 2, w // 2, num_filters))\n",
    "\n",
    "    for im_region, i, j in self.iterate_regions(input):\n",
    "      output[i, j] = np.amax(im_region, axis=(0, 1))\n",
    "\n",
    "    return output\n",
    "\n",
    "  def backprop(self, d_L_d_out):\n",
    "    '''\n",
    "    Performs a backward pass of the maxpool layer.\n",
    "    Returns the loss gradient for this layer's inputs.\n",
    "    - d_L_d_out is the loss gradient for this layer's outputs.\n",
    "    '''\n",
    "    d_L_d_input = np.zeros(self.last_input.shape)\n",
    "\n",
    "    for im_region, i, j in self.iterate_regions(self.last_input):\n",
    "      h, w, f = im_region.shape\n",
    "      amax = np.amax(im_region, axis=(0, 1))\n",
    "\n",
    "      for i2 in range(h):\n",
    "        for j2 in range(w):\n",
    "          for f2 in range(f):\n",
    "            # If this pixel was the max value, copy the gradient to it.\n",
    "            if im_region[i2, j2, f2] == amax[f2]:\n",
    "              d_L_d_input[i * 2 + i2, j * 2 + j2, f2] = d_L_d_out[i, j, f2]\n",
    "\n",
    "    return d_L_d_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Softmax:\n",
    "  # A standard fully-connected layer with softmax activation.\n",
    "\n",
    "  def __init__(self, input_len, nodes):\n",
    "    # We divide by input_len to reduce the variance of our initial values\n",
    "    self.weights = np.random.randn(input_len, nodes) / input_len\n",
    "    self.biases = np.zeros(nodes)\n",
    "\n",
    "  def forward(self, input):\n",
    "    '''\n",
    "    Performs a forward pass of the softmax layer using the given input.\n",
    "    Returns a 1d numpy array containing the respective probability values.\n",
    "    - input can be any array with any dimensions.\n",
    "    '''\n",
    "    self.last_input_shape = input.shape\n",
    "\n",
    "    input = input.flatten()\n",
    "    self.last_input = input\n",
    "\n",
    "    input_len, nodes = self.weights.shape\n",
    "\n",
    "    totals = np.dot(input, self.weights) + self.biases\n",
    "    self.last_totals = totals\n",
    "\n",
    "    exp = np.exp(totals)\n",
    "    return exp / np.sum(exp, axis=0)\n",
    "\n",
    "  def backprop(self, d_L_d_out, learn_rate):\n",
    "    '''\n",
    "    Performs a backward pass of the softmax layer.\n",
    "    Returns the loss gradient for this layer's inputs.\n",
    "    - d_L_d_out is the loss gradient for this layer's outputs.\n",
    "    - learn_rate is a float.\n",
    "    '''\n",
    "    # We know only 1 element of d_L_d_out will be nonzero\n",
    "    for i, gradient in enumerate(d_L_d_out):\n",
    "      if gradient == 0:\n",
    "        continue\n",
    "\n",
    "      # e^totals\n",
    "      t_exp = np.exp(self.last_totals)\n",
    "\n",
    "      # Sum of all e^totals\n",
    "      S = np.sum(t_exp)\n",
    "\n",
    "      # Gradients of out[i] against totals\n",
    "      d_out_d_t = -t_exp[i] * t_exp / (S ** 2)\n",
    "      d_out_d_t[i] = t_exp[i] * (S - t_exp[i]) / (S ** 2)\n",
    "\n",
    "      # Gradients of totals against weights/biases/input\n",
    "      d_t_d_w = self.last_input\n",
    "      d_t_d_b = 1\n",
    "      d_t_d_inputs = self.weights\n",
    "\n",
    "      # Gradients of loss against totals\n",
    "      d_L_d_t = gradient * d_out_d_t\n",
    "\n",
    "      # Gradients of loss against weights/biases/input\n",
    "      d_L_d_w = d_t_d_w[np.newaxis].T @ d_L_d_t[np.newaxis]\n",
    "      d_L_d_b = d_L_d_t * d_t_d_b\n",
    "      d_L_d_inputs = d_t_d_inputs @ d_L_d_t\n",
    "\n",
    "      # Update weights / biases\n",
    "      self.weights -= learn_rate * d_L_d_w\n",
    "      self.biases -= learn_rate * d_L_d_b\n",
    "\n",
    "      return d_L_d_inputs.reshape(self.last_input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def forward(image, label):\n",
    "  '''\n",
    "  Completes a forward pass of the CNN and calculates the accuracy and\n",
    "  cross-entropy loss.\n",
    "  - image is a 2d numpy array\n",
    "  - label is a digit\n",
    "  '''\n",
    "  # We transform the image from [0, 255] to [-0.5, 0.5] to make it easier\n",
    "  # to work with. This is standard practice.\n",
    "  out = conv.forward((image / 255) - 0.5)\n",
    "  out = pool.forward(out)\n",
    "  out = softmax.forward(out)\n",
    "\n",
    "  # Calculate cross-entropy loss and accuracy. np.log() is the natural log.\n",
    "  loss = -np.log(out[label])\n",
    "  acc = 1 if np.argmax(out) == label else 0\n",
    "\n",
    "  return out, loss, acc\n",
    "\n",
    "def train(im, label, lr=.005):\n",
    "  '''\n",
    "  Completes a full training step on the given image and label.\n",
    "  Returns the cross-entropy loss and accuracy.\n",
    "  - image is a 2d numpy array\n",
    "  - label is a digit\n",
    "  - lr is the learning rate\n",
    "  '''\n",
    "  # Forward\n",
    "  out, loss, acc = forward(im, label)\n",
    "\n",
    "  # Calculate initial gradient\n",
    "  gradient = np.zeros(10)\n",
    "  gradient[label] = -1 / out[label]\n",
    "\n",
    "  # Backprop\n",
    "  gradient = softmax.backprop(gradient, lr)\n",
    "  gradient = pool.backprop(gradient)\n",
    "  gradient = conv.backprop(gradient, lr)\n",
    "\n",
    "  return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from PIL import Image\n",
    "  \n",
    "x = str(0) \n",
    "\n",
    "IMAGE_PATH = r\"/Users/Josh/Desktop/CS 6375 - ML/project/images/\"\n",
    "BASE_PATH: str = \"https://personal.utdallas.edu/~kml190002/project-cs6375/train/\"\n",
    "\n",
    "for x in range(5):\n",
    "    x = str(x)\n",
    "    urllib.request.urlretrieve( BASE_PATH + x + '.jpg', x + \".jpg\")\n",
    "    img = Image.open(x+\".jpg\")\n",
    "    #print(x+\".jpg\")\n",
    "    img.save(IMAGE_PATH + x + \".jpeg\")\n",
    "    #img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in images\n",
    "image_list = []\n",
    "\n",
    "# specify the directory\n",
    "directory = Path(\"/Users/Josh/Desktop/CS 6375 - ML/project/images\")\n",
    "\n",
    "# get the list of all files in the directory\n",
    "image_list = [file for file in directory.iterdir() if file.is_file()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"/Users/Josh/Desktop/CS 6375 - ML/project/train.csv\")\n",
    "label_dict = {}\n",
    "for idx, row in labels.iterrows():\n",
    "    label_dict.update({row[\"image_name\"]: row[\"label\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get label\n",
    "label_dict[image_list[1].stem + \".jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 150)\n",
      "(148, 148, 8)\n",
      "(74, 74, 8)\n",
      "(6,)\n"
     ]
    }
   ],
   "source": [
    "grayImage = Image.open(image_list[0]).convert('L')\n",
    "imageArray = np.array(grayImage)\n",
    "\n",
    "print(imageArray.shape)\n",
    "   \n",
    "conv = Conv3x3(8)\n",
    "output = conv.forward(imageArray)\n",
    "print(output.shape)\n",
    "\n",
    "pool = MaxPool2()\n",
    "output = pool.forward(output)\n",
    "print(output.shape)\n",
    "\n",
    "softmax = Softmax(output.shape[0]**2 * 8, 6)\n",
    "output = softmax.forward(output)\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, image_list: List[Path], labels):\n",
    "        self.image_list = image_list        \n",
    "        self.labels = labels\n",
    "        self.softmax: Softmax = None\n",
    "        self.images = [Image.open(im) for im in self.image_list]\n",
    "        self.layers = []\n",
    "\n",
    "    def addLayer(self, conv: Conv3x3, pool: MaxPool2):\n",
    "        self.layers.append([conv, pool])\n",
    "\n",
    "    def numLayers(self):\n",
    "        return len(self.layers)\n",
    "    \n",
    "    def forward(self, layer, image, label= 0, pred = False):\n",
    "        '''\n",
    "        Completes a forward pass of the CNN and calculates the accuracy and\n",
    "        cross-entropy loss.\n",
    "        - image is a 2d numpy array\n",
    "        - label is a digit\n",
    "        '''\n",
    "        # We transform the image from [0, 255] to [-0.5, 0.5] to make it easier\n",
    "        # to work with. This is standard practice.\n",
    "        out = layer[0].forward((image / 255) - 0.5)\n",
    "        out = layer[1].forward(out)\n",
    "\n",
    "        # if pred == False:\n",
    "        #     # Calculate cross-entropy loss and accuracy. np.log() is the natural log.\n",
    "        #     loss = -np.log(out[label])\n",
    "        #     acc = 1 if np.argmax(out) == label else 0\n",
    "        # else:\n",
    "        #     loss = None\n",
    "        #     acc = None\n",
    "        loss = None\n",
    "        acc = None\n",
    "\n",
    "        return out, loss, acc\n",
    "\n",
    "    def train(self, lr = 0.005, it = 10):\n",
    "        \"\"\"Trains model for each layer on data\n",
    "\n",
    "        For each iteration, we take each image, and process forward on\n",
    "        all layers(conv + maxpool...)\n",
    "        Then when we're done with that, we get the softmax\n",
    "        Now we can do backprop, but this also needs loop over the layers(conv + maxpool...)\n",
    "        \"\"\"\n",
    "        # need to softcode number of labels\n",
    "        gradient = np.zeros(6)\n",
    "\n",
    "        for i in range(it):\n",
    "            print(i)\n",
    "            for im in self.image_list:\n",
    "                label = self.labels[im.stem + \".jpg\"]\n",
    "                input = np.array(Image.open(im))\n",
    "                \n",
    "                # this should only go through conv and maxpool. softmax should happen after\n",
    "                for l in self.layers:\n",
    "                    out, loss, acc = self.forward(layer = l, image = input, label = label, pred = False)\n",
    "                    # first input should be original image, then for every additional pass, the input\n",
    "                    # should be the previous layer's output\n",
    "                    input = out\n",
    "\n",
    "                print(out.shape)\n",
    "                \"\"\"If first iteration, then create a softmax class\n",
    "                    Args: \n",
    "                        out.shape[0]**2 * out.shape[2] => the previous output's image MASS.\n",
    "                            This is basically how many nodes there should be in the softmax\n",
    "\n",
    "                        6 => # of classes to look out for\n",
    "                \"\"\"\n",
    "                if i == 0:\n",
    "                    self.softmax = Softmax(out.shape[0]**2 * out.shape[2] , 6)\n",
    "                \n",
    "                # only run softmax AFTER all the layers full of conv and maxpool\n",
    "                out = self.softmax.forward(out)\n",
    "                \n",
    "                # not sure what to do with this\n",
    "                gradient[label] = -1 / out[label]\n",
    "\n",
    "                # Backprop\n",
    "                gradient = softmax.backprop(gradient, lr)\n",
    "                for l in self.layers:\n",
    "                    gradient = pool.backprop(gradient)\n",
    "                    gradient = conv.backprop(gradient, lr)\n",
    "            \n",
    "\n",
    "    def predict(self, image) -> int:\n",
    "        for l in self.layers:\n",
    "            out, loss, acc = forward(layer = l, image = image, label = 0, pred = True)\n",
    "\n",
    "        prob = self.softmax.forward(out)\n",
    "        pred = np.argmax(prob)\n",
    "\n",
    "        return pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN(image_list, label_dict)\n",
    "\n",
    "cnn.addLayer(Conv3x3(8), MaxPool2())\n",
    "cnn.addLayer(Conv3x3(8), MaxPool2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Figure out softmax layer, then test for backprop\n",
    "\n",
    "I tried to make this as general as possible, so it __should__ be able to have different number of filters for the different layers....\n",
    "\n",
    "Worth noting that the shape of output after all layers forward pass corresponds to the number of added layers. Play around with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(36, 36, 3)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/Josh/Desktop/CS 6375 - ML/project/CCNN.ipynb Cell 15\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Josh/Desktop/CS%206375%20-%20ML/project/CCNN.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m cnn\u001b[39m.\u001b[39;49mtrain()\n",
      "\u001b[1;32m/Users/Josh/Desktop/CS 6375 - ML/project/CCNN.ipynb Cell 15\u001b[0m in \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Josh/Desktop/CS%206375%20-%20ML/project/CCNN.ipynb#X35sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m gradient \u001b[39m=\u001b[39m softmax\u001b[39m.\u001b[39mbackprop(gradient, lr)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Josh/Desktop/CS%206375%20-%20ML/project/CCNN.ipynb#X35sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Josh/Desktop/CS%206375%20-%20ML/project/CCNN.ipynb#X35sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m     gradient \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39;49mbackprop(gradient)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Josh/Desktop/CS%206375%20-%20ML/project/CCNN.ipynb#X35sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m     gradient \u001b[39m=\u001b[39m conv\u001b[39m.\u001b[39mbackprop(gradient, lr)\n",
      "\u001b[1;32m/Users/Josh/Desktop/CS 6375 - ML/project/CCNN.ipynb Cell 15\u001b[0m in \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Josh/Desktop/CS%206375%20-%20ML/project/CCNN.ipynb#X35sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m       \u001b[39mfor\u001b[39;00m f2 \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(f):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Josh/Desktop/CS%206375%20-%20ML/project/CCNN.ipynb#X35sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m         \u001b[39m# If this pixel was the max value, copy the gradient to it.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Josh/Desktop/CS%206375%20-%20ML/project/CCNN.ipynb#X35sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m         \u001b[39mif\u001b[39;00m im_region[i2, j2, f2] \u001b[39m==\u001b[39m amax[f2]:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Josh/Desktop/CS%206375%20-%20ML/project/CCNN.ipynb#X35sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m           d_L_d_input[i \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \u001b[39m+\u001b[39m i2, j \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \u001b[39m+\u001b[39m j2, f2] \u001b[39m=\u001b[39m d_L_d_out[i, j, f2]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Josh/Desktop/CS%206375%20-%20ML/project/CCNN.ipynb#X35sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mreturn\u001b[39;00m d_L_d_input\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "cnn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.411199351448849"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = np.random.rand(3,3, 3)\n",
    "\n",
    "np.sum(input * np.random.rand(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "input = np.random.rand(10, 10, 3)\n",
    "\n",
    "print(input.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
